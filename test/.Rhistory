library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.1 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp70/full.data70', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.3 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp70/full.data70', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
## full.data = (P+S)(Q+T)
## full.data1 = (P+S)Q
## full.data2 = exp(-abs(rating))
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.2 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp70/full.data80', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.2 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp80/full.data80', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
## full.data = (P+S)(Q+T)
## full.data1 = (P+S)Q
## full.data2 = exp(-abs(rating))
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
setwd("~/Documents/Research/2020W/DeepRec-master/test")
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp80.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp90.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp95.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.05 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp95/full.data95', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
## full.data = (P+S)(Q+T)
## full.data1 = (P+S)Q
## full.data2 = exp(-abs(rating))
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=1
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.01 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp95/full.data99', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
#3.12.2016
#Run simulation seriously
#Try to replicate cold-start problem
setwd("~/Documents/Research/2020W/DeepRec-master/data/")
library(MASS)
library(doParallel)
library(foreach)
library(bigmemory)
library(bigalgebra)
library(Rcpp)
library(RcppArmadillo)
#cl=detectCores()
cl=16
registerDoParallel(cores = cl)
getDoParWorkers()
source("subfunctions for simulation.R")
sourceCpp('RcppArmadillosample.cpp')
source('subfunctions for Rcpp.R')
#basic settings
n=650
m=660
B=13	#the number of user clusters
C=11	#the number of item clusters
Ktrue=3
user.clustersize=n/B
item.clustersize=m/C
occup=rep(1:B,each=user.clustersize)	#Input: userID, Return: Occupation
genre=rep(1:C,each=item.clustersize)	#Input: itemID, Return: Genre
Bhat=B
Chat=C
S=100 #Specify the number of replications
K=Ktrue
options(bigmemory.allow.dimnames=TRUE)
s=97
while(s<S+1){
set.seed(888+s)
P=big.matrix(n,Ktrue)
P[,]=matrix(rnorm(n*Ktrue,0,1),n,Ktrue)
Q=big.matrix(m,Ktrue)
Q[,]=matrix(rnorm(m*Ktrue,0,1),m,Ktrue)
O=big.matrix(B,Ktrue)
O[,]=seq(-3,3,by=0.5)%*%t(rep(1,Ktrue))
G=big.matrix(C,Ktrue)
G[,]=seq(-3,3,by=0.6)%*%t(rep(1,Ktrue)) # for full.data
G[,]=rep(0, 11)%*%t(rep(1,Ktrue)) # for full.data1
#R=(P+O[occup,])%*%t(Q+G[genre,])/3+matrix(rnorm(n*m,0,0.5),n,m)
# # #
#generating missing pattern
J=n*m*0.01 #Specify (1-missing.rate)
full.data=NULL
full.data=foreach(j=1:J,.combine='cbind') %dopar%{
generate.rating(full.data,P,Q,O,G,j)
}
full.data=as.big.matrix(t(full.data))
#full.data=cbind(sample(1:n,J,replace=TRUE),sample(1:m,J,replace=TRUE),rbinom(J,5,0.63)+1)
colnames(full.data) = c('user_id', 'item_id', 'rating')
#full.data[, 3] = exp(-abs(full.data[, 3])) # for data2
save_path = paste('data_sp99/full.data99', 888+s,'.csv', sep='')
write.csv(full.data[], save_path, row.names=FALSE)
s = s+1
}
## full.data = (P+S)(Q+T)
## full.data1 = (P+S)Q
## full.data2 = exp(-abs(rating))
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
setwd("~/Documents/Research/2020W/DeepRec-master/test")
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp80.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp90.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp95.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data80_sp99.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp99.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70_2.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data95_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data95_sp80.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data95_sp90.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data95_sp99.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data95_sp95.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
rmse = read.csv('log.test_IAutoRec_filled_new_L200_50n_data70_sp70.txt', sep = " ", header=FALSE)  #log.test_IAutoRec_filled_new_L200_50n_sp_0.5mis_rd.txt
dim(rmse)
apply(rmse, 2, mean)
apply(rmse,2, sd)
